{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_all(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, j)\n",
    "    return text\n",
    "\n",
    "\n",
    "def string_to_float(a):\n",
    "    s1 = replace_all(a, rep)\n",
    "    s1 = s1.split(' ')\n",
    "    s1 = [float(i) for i in s1]\n",
    "    return s1\n",
    "\n",
    "\n",
    "def load_data(data_name):\n",
    "    pkl_file = open(data_name + '.pkl', 'rb')\n",
    "    data = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FASTA sequences, polarity and radicals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record FASTA df: OK\n"
     ]
    }
   ],
   "source": [
    "#  Read fasta-files\n",
    "with open('./train/train.fasta', 'r') as myfile:\n",
    "    data = myfile.read().replace('\\n', '')\n",
    "    \n",
    "    \n",
    "#  Create dictionaries for classifying all aminoacids according to classe from wiki (polarity and radicals)\n",
    "rad_dic = {'G': '0', 'L': '0', 'Y': '1', 'S': '2', 'E': '3', 'Q': '4', 'D': '3', 'N': '4', 'F': '1',\n",
    "       'A': '0', 'K': '5', 'R': '5', 'H': '6', 'C': '7', 'V': '0', 'P': '6', 'W': '6', 'I': '0', 'M': '7', 'T': '2'}\n",
    "pol_dic = {'G': '0', 'L': '0', 'Y': '1', 'S': '1', 'E': '2', 'Q': '1', 'D': '2', 'N': '1', 'F': '0',\n",
    "        'A': '0', 'K': '1', 'R': '1', 'H': '3', 'C': '0', 'V': '0', 'P': '0', 'W': '0', 'I': '0', 'M': '0', 'T': '1'}\n",
    "\n",
    "\n",
    "bad_prot = []\n",
    "pdb_name = ''\n",
    "seq = ''\n",
    "j = 0\n",
    "fasta_df = pd.DataFrame()\n",
    "mm = 0\n",
    "\n",
    "\n",
    "#  Record protein name, fasta sequences, radical and polarity classes into dataframe\n",
    "for i in range(len(data) - 1):\n",
    "    seq = ''\n",
    "    \n",
    "    if data[i] == '$' and data[i+5] == '%':\n",
    "        pdb_name = data[i+1:i+5]\n",
    "        \n",
    "    if data[i] == '%':\n",
    "        j = i+1\n",
    "        \n",
    "        while data[j] != '$' and j != len(data)-1:\n",
    "            \n",
    "            if data[j] not in rad_dic:\n",
    "                if pdb_name not in bad_prot:\n",
    "                    bad_prot.append(pdb_name)\n",
    "            \n",
    "            seq += data[j]\n",
    "            j = j + 1\n",
    "            \n",
    "            if j == len(data) - 1:\n",
    "                seq += data[j]\n",
    "                \n",
    "        if len(seq) > mm:\n",
    "            mm = len(seq)\n",
    "            \n",
    "        replace_all(seq, rad_dic)\n",
    "        temp_df = pd.DataFrame({'pdb_name': [pdb_name], 'FASTA':[seq], 'Radical':[replace_all(seq, rad_dic)]\n",
    "                           , 'Polarity':[replace_all(seq, pol_dic)]})\n",
    "        fasta_df = pd.concat([fasta_df, temp_df], ignore_index=True)\n",
    "        \n",
    "        \n",
    "print(\"Record FASTA df: OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSSM matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record PSSM df: OK\n"
     ]
    }
   ],
   "source": [
    "#  Read PSSM matrix and also record it into dataframe\n",
    "file = open('./train/train.pssm', 'r')\n",
    "pssm = file.readlines()\n",
    "rep = {'G ':'', 'L ':'', 'Y ':'', 'S ':'', 'E ':'', 'Q ':'', 'D ':'', 'N ':'', 'F ':'', \n",
    "       'A ':'', 'K ':'', 'R ':'', 'H ':'', 'C ':'', 'V ':'', 'P ':'', 'W ':'', 'I ':'', 'M ':'', 'X ':'', 'T ':'', '\\n':''}\n",
    "\n",
    "\n",
    "pssm_df = pd.DataFrame()\n",
    "gd = []\n",
    "j = 0\n",
    "\n",
    "\n",
    "for i in range(len(pssm)-1, -1, -1):\n",
    "    \n",
    "    if pssm[i][0] == '>':\n",
    "        gd = list(reversed(gd))\n",
    "        temp_df = pd.DataFrame({'PSSM': [gd]})\n",
    "        pssm_df = pd.concat([pssm_df, temp_df], ignore_index = True)\n",
    "        gd = []\n",
    "        \n",
    "    if pssm[i][0]!='>':\n",
    "        gd.append(string_to_float(pssm[i]))\n",
    "\n",
    "        \n",
    "print(\"Record PSSM df: OK\")\n",
    "\n",
    "\n",
    "pssm_df = pssm_df.iloc[::-1]\n",
    "pssm_df = pssm_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pssm_df['PSSM'][7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solvent accessibility and secondary structure classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record SS and ACC df: OK\n"
     ]
    }
   ],
   "source": [
    "# Read solvent accessibility and secondary structure classes\n",
    "file = open('./train/train.acc', 'r')\n",
    "acc = file.readlines()\n",
    "\n",
    "\n",
    "file = open('./train/train.ss', 'r')\n",
    "ss = file.readlines()\n",
    "ss_acc_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in range(len(ss)):\n",
    "    if i%2 != 0:\n",
    "        temp = pd.DataFrame({'SS': [ss[i].replace('\\n', '')], 'ACC':[acc[i].replace('\\n', '')]})\n",
    "        ss_acc_df = pd.concat([ss_acc_df, temp], ignore_index=True)\n",
    "        \n",
    "        \n",
    "print(\"Record SS and ACC df: OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All to one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop \"bad proteins\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_matrix = load_data('two_matrix_200')\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "result = pd.concat([fasta_df, ss_acc_df, pssm_df], axis=1, sort=False)\n",
    "print(\"Concatenate dfs: OK\")\n",
    "\n",
    "#  Delete proteins with untypical aminoacids in sequence or the ones with different sequence size\n",
    "bad = []\n",
    "\n",
    "for i in range(len(two_matrix)):\n",
    "    for j in range(len(result)):\n",
    "        \n",
    "        if two_matrix[i][0] == result['pdb_name'][j]:\n",
    "            \n",
    "            if len(two_matrix[i][2]) != len(result.FASTA[j]) or result.pdb_name.iloc[i] in bad_prot:\n",
    "                bad.append(j)\n",
    "        \n",
    "result = result.drop(bad)\n",
    "result = result.reset_index(drop=True)\n",
    "print(\"Drop bad proteins: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.pdb_name.to_csv('good_prot.csv', index=False)\n",
    "result.to_csv('pdb_and_features.csv', header='pdb_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Transform categorical data into binarized labels in a one-vs-all fashion\n",
    "asd = []\n",
    "bad = []\n",
    "\n",
    "for i in range(len(result)):\n",
    "    features = []\n",
    "    \n",
    "    features.append(list(result.FASTA[i]))\n",
    "    features.append(list(result.SS[i]))\n",
    "    features.append(list(result.ACC[i]))\n",
    "    features.append(list(result.Polarity[i]))\n",
    "    features.append(list(result.Radical[i]))\n",
    "    \n",
    "    if len(np.unique([len(features[0]), len(features[1]), len(features[2]), len(features[3]), len(features[4])])) > 1:\n",
    "        bad.append(i)\n",
    "        continue\n",
    "    \n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb1 = preprocessing.LabelBinarizer()\n",
    "    lb2 = preprocessing.LabelBinarizer()\n",
    "    lb3 = preprocessing.LabelBinarizer()\n",
    "    lb4 = preprocessing.LabelBinarizer()\n",
    "    \n",
    "    lb.fit(['G', 'L', 'Y', 'S', 'E', 'Q', 'D', 'N', 'F', 'A', 'K', 'R', 'H', 'C', 'V', 'P', 'W', 'I', 'M', 'T'])\n",
    "    a = lb.transform(features[0])\n",
    "    lb1.fit(['C', 'H', 'E'])\n",
    "    b = lb1.transform(features[1])\n",
    "    lb3.fit(['e', '-'])\n",
    "    c = lb3.transform(features[2])\n",
    "    lb2.fit(['0', '1', '2', '3', '4', '5', '6', '7'])\n",
    "    d = lb2.transform(features[3])\n",
    "    lb4.fit(['0', '1', '2', '3'])\n",
    "    e = lb4.transform(features[4])\n",
    "    pdb1 = [result['pdb_name'][i], np.concatenate((a, b, c, d, e, result.PSSM[i]), axis=1)]\n",
    "    asd.append(pdb1)\n",
    "    \n",
    "print(\"Binarized labels: OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record data: OK\n"
     ]
    }
   ],
   "source": [
    "#  Save final data into pickle file\n",
    "output = open('train_data.pkl', 'wb')\n",
    "pickle.dump(asd, output)\n",
    "output.close()\n",
    "print(\"Record data: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
