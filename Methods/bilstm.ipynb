{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM and LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, LSTM, Embedding, Activation, Add\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU, ReLU\n",
    "from keras.regularizers import l2 # L2-regularisation\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been adapted for Kaggle platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_name):\n",
    "    pkl_file = open(data_name + '.pkl', 'rb')\n",
    "    data = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    return data\n",
    "\n",
    "print('Loading data...')\n",
    "folder = '../input/neuraldataset2540/neural_'\n",
    "\n",
    "train = np.array(load_data(folder + 'train'))\n",
    "train_label = load_data(folder + 'train_label')\n",
    "test = np.array(load_data(folder + 'test'))\n",
    "test_label = load_data(folder + 'test_label')\n",
    "valid = np.array(load_data(folder + 'valid'))\n",
    "valid_label = load_data(folder + 'valid_label')\n",
    "print('Data are loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping for correct input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reshape(train.shape[0], train.shape[1], train.shape[2])\n",
    "test = test.reshape(test.shape[0], test.shape[1], test.shape[2])\n",
    "valid = valid.reshape(valid.shape[0], valid.shape[1], valid.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilstm(input_shape, output_shape, mm):\n",
    "    \n",
    "    l2_lambda = 0.0001\n",
    "    \n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    layer = (Bidirectional(LSTM(8, return_sequences=True)))(inputs)\n",
    "    layer = (Bidirectional(LSTM(16)))(layer)\n",
    "\n",
    "    output = (Dense(mm, activation = 'linear', W_regularizer = l2(l2_lambda)))(layer) \n",
    "    output = (LeakyReLU())(output)\n",
    "    output = (Dropout(0.3))(output)\n",
    "    \n",
    "    finish = []\n",
    "    for i in range(int((mm ** 2 - mm ) / 2)):\n",
    "        output = (Dense(2, activation = 'softmax', name = 'main_output' + str(i)))(output)\n",
    "        finish.append(output)\n",
    "\n",
    "    model = Model(inputs = [inputs], outputs = finish)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer = 'adam',\n",
    "        loss = 'binary_crossentropy'\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(input_shape, output_shape, mm):\n",
    "    \n",
    "    l2_lambda = 0.01\n",
    "    \n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    layer = (LSTM(32, return_sequences=True))(inputs)\n",
    "    layer = (LSTM(64, return_sequences=True))(layer)\n",
    "    layer = (LSTM(128))(layer)\n",
    "        \n",
    "    layer = (BatchNormalization())(layer)\n",
    "    output = (Dense(128, activation = 'linear', W_regularizer = l2(l2_lambda)))(layer) \n",
    "    output = (ReLU())(layer)\n",
    "    output = (Dropout(0.3))(output)\n",
    "    \n",
    "    finish = []\n",
    "    for i in range(int((mm ** 2 - mm ) / 2)):\n",
    "        output = (Dense(2, activation = 'softmax', name = 'main_output' + str(i)))(output)\n",
    "        finish.append(output)\n",
    "\n",
    "    model = Model(inputs = [inputs], outputs = finish)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer = 'adam',\n",
    "        loss = 'categorical_crossentropy'\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training depending on the model (lstm or bilstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 20\n",
    "mm = 40\n",
    "\n",
    "model = lstm((train.shape[1], train.shape[2]), 2, mm)\n",
    "\n",
    "history = model.fit(train, list(train_label), batch_size = batch_size, epochs = epochs, verbose = 0,\n",
    "                          validation_data=(valid, list(valid_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(test)\n",
    "\n",
    "print(np.shape(predicted))\n",
    "print(np.shape(test_label))\n",
    "\n",
    "output = open('predicted_bi' + '.pkl', 'wb')\n",
    "pickle.dump(predicted, output)\n",
    "output.close()\n",
    "\n",
    "output = open('test_bi' + '.pkl', 'wb')\n",
    "pickle.dump(test_label, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig('bilstm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
