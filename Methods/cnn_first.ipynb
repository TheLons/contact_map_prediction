{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, LSTM, Embedding, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.regularizers import l2 # L2-regularisation\n",
    "from keras.activations import sigmoid\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been adapted for Kaggle platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_name):\n",
    "    pkl_file = open(data_name + '.pkl', 'rb')\n",
    "    data = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    return data\n",
    "\n",
    "print('Loading data...')\n",
    "folder = '../input/neuraldataset2540/'\n",
    "\n",
    "train = load_data(folder + 'neural_train')\n",
    "train_label = load_data(folder + 'neural_train_label')\n",
    "test = load_data(folder + 'neural_test')\n",
    "test_label = load_data(folder + 'neural_test_label')\n",
    "valid = load_data(folder + 'neural_valid')\n",
    "valid_label = load_data(folder + 'neural_valid_label')\n",
    "print('Data are loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "l2_lambda = 0.0001\n",
    "batch_size = 8\n",
    "epochs = 25\n",
    "reg = l2(l2_lambda)\n",
    "init=\"he_normal\"\n",
    "mm1 = 40\n",
    "mm = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(input_shape, mm, output_shape):\n",
    "\n",
    "    input_layer = Input(input_shape)\n",
    "\n",
    "    layer3 = (Conv2D(32, (mm, 5), activation='linear', W_regularizer=l2(l2_lambda), padding='same'))(input_layer)\n",
    "    layer3 = (LeakyReLU(alpha=0.1))(layer3)\n",
    "    layer3 = (Conv2D(64, (mm, 5), activation='linear', W_regularizer=l2(l2_lambda), padding='same'))(layer3)\n",
    "    layer3 = (LeakyReLU(alpha=0.1))(layer3)\n",
    "    layer3 = (MaxPooling2D(pool_size=(2, 2),padding='same'))(layer3)\n",
    "    layer3 = (Dropout(0.3))(layer3)\n",
    "\n",
    "    layer4 = (Flatten())(layer3)\n",
    "    layer4 = (Dense((mm), activation='linear', W_regularizer=l2(l2_lambda)))(layer4)\n",
    "    layer4 = (LeakyReLU(alpha=0.1))(layer4)\n",
    "    layer4 = (Dropout(0.3))(layer4)\n",
    "    finish = []\n",
    "\n",
    "    for i in range(int((mm ** 2 - mm) / 2)):\n",
    "        output = Dense(output_shape, activation='softmax', name='main_output'+str(i))(layer4)\n",
    "        finish.append(output)\n",
    "\n",
    "    model = Model(inputs=[input_layer], outputs=output)\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer=keras.optimizers.Adam(lr=0.001))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn((train.shape[1], train.shape[2], 1), mm, 2)\n",
    "\n",
    "train_dropout = model.fit(train, train_label, batch_size = batch_size, epochs = epochs, verbose = 1,\n",
    "                          validation_data = (np.array(valid), valid_label))\n",
    "\n",
    "predicted = model.predict(test)\n",
    "\n",
    "print(np.shape(predicted))\n",
    "print(np.shape(test_label))\n",
    "\n",
    "output = open('predicted2' + '.pkl', 'wb')\n",
    "pickle.dump(predicted, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(train_dropout.history['loss'])\n",
    "plt.plot(train_dropout.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
